{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_CollectionsBase.get() got an unexpected keyword argument 'tenant'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m client = get_weaviate_client()\n\u001b[32m      4\u001b[39m tenant_id = \u001b[33m\"\u001b[39m\u001b[33mtenant-xyz\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m results = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollections\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDocumentChunk\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m)\u001b[49m.query.hybrid(\n\u001b[32m      7\u001b[39m     query=\u001b[33m\"\u001b[39m\u001b[33mWhat are the key terms?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     limit=\u001b[32m5\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results.objects:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(res.properties.get(\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m[No content]\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mTypeError\u001b[39m: _CollectionsBase.get() got an unexpected keyword argument 'tenant'"
     ]
    }
   ],
   "source": [
    "from ingramdocai.services.weaviate_client import get_weaviate_client\n",
    "\n",
    "client = get_weaviate_client()\n",
    "tenant_id = \"tenant-xyz\"\n",
    "\n",
    "results = client.collections.get(\"DocumentChunk\", tenant=tenant_id).query.hybrid(\n",
    "    query=\"What are the key terms?\",\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "for res in results.objects:\n",
    "    print(res.properties.get(\"content\", \"[No content]\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-12 09:30:47,412 [INFO] inject-document: ‚è≥ Checking and initializing database schema if needed...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-12 09:30:47,414 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-07-12 09:30:47,415 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"document_sessions\")\n",
      "2025-07-12 09:30:47,416 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-07-12 09:30:47,420 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-12 09:30:47,422 [INFO] inject-document: Injecting 2 document(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-12 09:30:47,424 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-07-12 09:30:47,425 INFO sqlalchemy.engine.Engine SELECT document_sessions.session_id AS document_sessions_session_id, document_sessions.tenant_id AS document_sessions_tenant_id, document_sessions.user_id AS document_sessions_user_id, document_sessions.file_path AS document_sessions_file_path, document_sessions.status AS document_sessions_status, document_sessions.chunk_count AS document_sessions_chunk_count, document_sessions.error_message AS document_sessions_error_message, document_sessions.created_at AS document_sessions_created_at, document_sessions.updated_at AS document_sessions_updated_at \n",
      "FROM document_sessions \n",
      "WHERE document_sessions.session_id = ?\n",
      " LIMIT ? OFFSET ?\n",
      "2025-07-12 09:30:47,426 INFO sqlalchemy.engine.Engine [cached since 1475s ago] ('session-localtest-001', 1, 0)\n",
      "2025-07-12 09:30:47,427 INFO sqlalchemy.engine.Engine UPDATE document_sessions SET status=?, updated_at=? WHERE document_sessions.session_id = ?\n",
      "2025-07-12 09:30:47,428 INFO sqlalchemy.engine.Engine [cached since 1381s ago] ('in_progress', '2025-07-12 14:30:47.423267', 'session-localtest-001')\n",
      "2025-07-12 09:30:47,430 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/tmp/ipykernel_38167/3682873400.py:52: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  created_at=datetime.utcnow(),\n",
      "/private/tmp/ipykernel_38167/3682873400.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  updated_at=datetime.utcnow()\n",
      "2025-07-12 09:30:47,431 [INFO] save_session_record: Session session-localtest-001 updated ‚Üí status=in_progress\n",
      "2025-07-12 09:30:47,431 [INFO] save_session_record: Database session closed in SaveSessionRecordTool\n",
      "2025-07-12 09:30:47,432 [INFO] inject-document: Processing file: /Users/gabrielohaike/Desktop/IngramDocAI/tests/sample_docs/ingram_fact_sheet.pdf\n",
      "<frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
      "<frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
      "<frozen importlib._bootstrap>:488: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n",
      "2025-07-12 09:30:51,106 [INFO] document_processor: Processed 6 chunks from /Users/gabrielohaike/Desktop/IngramDocAI/tests/sample_docs/ingram_fact_sheet.pdf\n",
      "2025-07-12 09:30:51,106 [INFO] inject-document: Processing file: /Users/gabrielohaike/Desktop/IngramDocAI/tests/sample_docs/test_contract.txt\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "2025-07-12 09:30:51,110 [INFO] document_processor: Processed 1 chunks from /Users/gabrielohaike/Desktop/IngramDocAI/tests/sample_docs/test_contract.txt\n",
      "/private/tmp/ipykernel_38167/3682873400.py:84: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"created_at\": datetime.utcnow().isoformat() + \"Z\"\n",
      "2025-07-12 09:30:51,110 [INFO] inject-document: Prepared 7 chunks for upsert\n",
      "2025-07-12 09:30:51,398 [INFO] weaviate-class-manager: [tenant=tenant-xyz] Syncing properties on existing class 'DocumentChunk'\n",
      "2025-07-12 09:30:51,441 [INFO] weaviate-class-manager: [tenant=tenant-xyz] Property sync complete for class 'DocumentChunk'\n",
      "2025-07-12 09:30:51,576 [INFO] weaviate-class-manager: [tenant=tenant-xyz] Already registered\n",
      "2025-07-12 09:30:51,627 [INFO] weaviate-class-manager: [tenant=tenant-xyz] Syncing properties on existing class 'DocumentChunk'\n",
      "2025-07-12 09:30:51,668 [INFO] weaviate-class-manager: [tenant=tenant-xyz] Property sync complete for class 'DocumentChunk'\n",
      "2025-07-12 09:30:51,761 [INFO] weaviate-class-manager: [tenant=tenant-xyz] Already registered\n",
      "2025-07-12 09:30:51,763 [INFO] document-chunk-upsert: [tenant=tenant-xyz] Tenant already exists.\n",
      "2025-07-12 09:30:53,630 [INFO] document-chunk-upsert: [tenant=tenant-xyz] Upsert complete: 7/7 document chunks.\n",
      "2025-07-12 09:30:53,631 [INFO] inject-document: Upserted 7 document chunks into Weaviate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-12 09:30:53,631 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-07-12 09:30:53,632 INFO sqlalchemy.engine.Engine SELECT document_sessions.session_id AS document_sessions_session_id, document_sessions.tenant_id AS document_sessions_tenant_id, document_sessions.user_id AS document_sessions_user_id, document_sessions.file_path AS document_sessions_file_path, document_sessions.status AS document_sessions_status, document_sessions.chunk_count AS document_sessions_chunk_count, document_sessions.error_message AS document_sessions_error_message, document_sessions.created_at AS document_sessions_created_at, document_sessions.updated_at AS document_sessions_updated_at \n",
      "FROM document_sessions \n",
      "WHERE document_sessions.session_id = ?\n",
      " LIMIT ? OFFSET ?\n",
      "2025-07-12 09:30:53,632 INFO sqlalchemy.engine.Engine [cached since 1481s ago] ('session-localtest-001', 1, 0)\n",
      "2025-07-12 09:30:53,633 INFO sqlalchemy.engine.Engine UPDATE document_sessions SET status=?, chunk_count=?, updated_at=? WHERE document_sessions.session_id = ?\n",
      "2025-07-12 09:30:53,633 INFO sqlalchemy.engine.Engine [cached since 1381s ago] ('completed', 7, '2025-07-12 14:30:53.631506', 'session-localtest-001')\n",
      "2025-07-12 09:30:53,634 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/tmp/ipykernel_38167/3682873400.py:101: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  updated_at=datetime.utcnow()\n",
      "2025-07-12 09:30:53,634 [INFO] save_session_record: Session session-localtest-001 updated ‚Üí status=completed\n",
      "2025-07-12 09:30:53,634 [INFO] save_session_record: Database session closed in SaveSessionRecordTool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Document Injection Completed ======\n",
      "Session ID: session-localtest-001\n",
      "Total Chunks: 7\n",
      "==========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from ingramdocai.core.logger import setup_logger\n",
    "from ingramdocai.services.document_processing_service import DocumentProcessingService\n",
    "from ingramdocai.tools.save_session_record import SaveSessionRecordTool\n",
    "from ingramdocai.services.weaviate_class_manager import sync_schema, ensure_tenant_registered\n",
    "from ingramdocai.services.document_upsert_embedding import bulk_upsert_document_chunks\n",
    "from ingramdocai.persistence.db import Base, engine\n",
    "from ingramdocai.persistence.models import DocumentSession\n",
    "\n",
    "logger = setup_logger(\"inject-document\")\n",
    "\n",
    "\n",
    "class TestInjectRunner:\n",
    "    def __init__(self):\n",
    "        self.state = type(\"State\", (), {\n",
    "            \"session_id\": \"session-localtest-001\",\n",
    "            \"chunk_count\": 0,\n",
    "            \"user_info\": {\n",
    "                \"tenant_id\": \"tenant-xyz\",\n",
    "                \"user_id\": \"user-123\"\n",
    "            }\n",
    "        })()\n",
    "\n",
    "    def inject_document(self):\n",
    "        logger.info(\"‚è≥ Checking and initializing database schema if needed...\")\n",
    "        Base.metadata.create_all(bind=engine)\n",
    "\n",
    "        try:\n",
    "            sample_docs_dir = Path(\"tests/sample_docs\").resolve()\n",
    "            sample_docs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            file_paths = [str(f) for f in sample_docs_dir.glob(\"*\") if f.is_file()]\n",
    "            if not file_paths:\n",
    "                logger.warning(\"‚ö†Ô∏è No documents found in tests/sample_docs. Nothing to process.\")\n",
    "                return\n",
    "\n",
    "            session_id = self.state.session_id\n",
    "            tenant_id = self.state.user_info.get(\"tenant_id\")\n",
    "            user_id = self.state.user_info.get(\"user_id\")\n",
    "\n",
    "            logger.info(f\"Injecting {len(file_paths)} document(s)\")\n",
    "            logger.debug(f\"Session ‚Üí ID: {session_id}, Tenant: {tenant_id}, User: {user_id}\")\n",
    "\n",
    "            SaveSessionRecordTool()._run(\n",
    "                session_id=session_id,\n",
    "                tenant_id=tenant_id,\n",
    "                user_id=user_id,\n",
    "                file_path=\";\".join(file_paths),\n",
    "                status=\"in_progress\",\n",
    "                created_at=datetime.utcnow(),\n",
    "                updated_at=datetime.utcnow()\n",
    "            )\n",
    "\n",
    "            processor = DocumentProcessingService()\n",
    "            all_chunks = []\n",
    "\n",
    "            for file_path in file_paths:\n",
    "                logger.info(f\"Processing file: {file_path}\")\n",
    "                result = processor.process(file_path)\n",
    "                for chunk in result[\"chunks\"]:\n",
    "                    chunk.metadata.update({\n",
    "                        \"file_name\": Path(file_path).name,\n",
    "                        \"file_type\": Path(file_path).suffix.lstrip(\".\"),\n",
    "                        \"tenant_id\": tenant_id,\n",
    "                        \"session_id\": session_id\n",
    "                    })\n",
    "                    all_chunks.append(chunk)\n",
    "\n",
    "            if not all_chunks:\n",
    "                logger.warning(\"‚ö†Ô∏è No chunks generated from input documents.\")\n",
    "                return\n",
    "\n",
    "            payloads = [{\n",
    "                \"tenant_id\": chunk.metadata[\"tenant_id\"],\n",
    "                \"session_id\": chunk.metadata[\"session_id\"],\n",
    "                \"file_name\": chunk.metadata[\"file_name\"],\n",
    "                \"file_type\": chunk.metadata[\"file_type\"],\n",
    "                \"text\": chunk.page_content,\n",
    "                \"chunk_id\": f\"{i+1}\",\n",
    "                \"char_count\": len(chunk.page_content),\n",
    "                \"source\": \"document_upload\",\n",
    "                \"created_at\": datetime.utcnow().isoformat() + \"Z\"\n",
    "            } for i, chunk in enumerate(all_chunks)]\n",
    "\n",
    "            logger.info(f\"Prepared {len(payloads)} chunks for upsert\")\n",
    "\n",
    "            sync_schema(tenant_id)\n",
    "            ensure_tenant_registered(tenant_id)\n",
    "\n",
    "            bulk_upsert_document_chunks(payloads)\n",
    "            logger.info(f\"Upserted {len(payloads)} document chunks into Weaviate\")\n",
    "\n",
    "            SaveSessionRecordTool()._run(\n",
    "                session_id=session_id,\n",
    "                tenant_id=tenant_id,\n",
    "                user_id=user_id,\n",
    "                status=\"completed\",\n",
    "                chunk_count=len(payloads),\n",
    "                updated_at=datetime.utcnow()\n",
    "            )\n",
    "\n",
    "            self.state.chunk_count = len(payloads)\n",
    "\n",
    "            print(\"\\n====== Document Injection Completed ======\")\n",
    "            print(f\"Session ID: {session_id}\")\n",
    "            print(f\"Total Chunks: {self.state.chunk_count}\")\n",
    "            print(\"==========================================\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Injection failed: {str(e)}\")\n",
    "            SaveSessionRecordTool()._run(\n",
    "                session_id=self.state.session_id,\n",
    "                tenant_id=self.state.user_info.get(\"tenant_id\"),\n",
    "                user_id=self.state.user_info.get(\"user_id\"),\n",
    "                status=\"failed\",\n",
    "                error_message=str(e),\n",
    "                updated_at=datetime.utcnow()\n",
    "            )\n",
    "            raise\n",
    "\n",
    "\n",
    "# ‚úÖ Entry Point\n",
    "if __name__ == \"__main__\":\n",
    "    runner = TestInjectRunner()\n",
    "    runner.inject_document()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Querying chunks for tenant 'tenant-xyz' with query: 'What is this contract about?'\n",
      "‚úÖ Found 3 result(s):\n",
      "\n",
      "üîπ Result #1\n",
      "üìÑ File: test_contract.txt\n",
      "üìë Text: This is a fallback sample contract for testing Weaviate injection.\n",
      "üì¶ Session: session-localtest-001\n",
      "üìÖ Created: 2025-07-12 14:30:51.110777+00:00\n",
      "--------------------------------------------------------------------------------\n",
      "üîπ Result #2\n",
      "üìÑ File: test_contract.txt\n",
      "üìë Text: This is a fallback sample contract for testing Weaviate injection.\n",
      "üì¶ Session: session-localtest-001\n",
      "üìÖ Created: 2025-07-12 14:09:17.667995+00:00\n",
      "--------------------------------------------------------------------------------\n",
      "üîπ Result #3\n",
      "üìÑ File: ingram_fact_sheet.pdf\n",
      "üìë Text: ÔÄº Solid balance sheet and flexible structure \n",
      "o Quarter-end cash and cash equivalents balance of $891 million \n",
      "o Continued focus on working capital management  \n",
      " \n",
      "ÔÄº $400 million share repurchase program \n",
      "o 12.5 million shares of common stock purchased as of February 8, 2012 for approximately $226 million\n",
      "üì¶ Session: session-localtest-001\n",
      "üìÖ Created: 2025-07-12 14:30:51.110775+00:00\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ingramdocai.services.weaviate_client import get_weaviate_client\n",
    "\n",
    "def query_chunks(tenant_id: str, query: str, limit: int = 3):\n",
    "    client = get_weaviate_client()\n",
    "\n",
    "    print(f\"üîç Querying chunks for tenant '{tenant_id}' with query: '{query}'\")\n",
    "\n",
    "    # ‚úÖ Proper multi-tenant usage\n",
    "    collection = client.collections.get(\"DocumentChunk\").with_tenant(tenant_id)\n",
    "\n",
    "    results = collection.query.hybrid(\n",
    "        query=query,\n",
    "        limit=limit\n",
    "    )\n",
    "\n",
    "    if not results.objects:\n",
    "        print(\"‚ùå No chunks found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"‚úÖ Found {len(results.objects)} result(s):\\n\")\n",
    "\n",
    "    for i, obj in enumerate(results.objects, start=1):\n",
    "        props = obj.properties\n",
    "        print(f\"üîπ Result #{i}\")\n",
    "        print(f\"üìÑ File: {props.get('file_name')}\")\n",
    "        print(f\"üìë Text: {props.get('text')}\")\n",
    "        print(f\"üì¶ Session: {props.get('session_id')}\")\n",
    "        print(f\"üìÖ Created: {props.get('created_at')}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query_chunks(tenant_id=\"tenant-xyz\", query=\"What is this contract about?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-12 10:54:05,619 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-07-12 10:54:05,627 INFO sqlalchemy.engine.Engine SELECT document_sessions.session_id AS document_sessions_session_id, document_sessions.tenant_id AS document_sessions_tenant_id, document_sessions.user_id AS document_sessions_user_id, document_sessions.file_path AS document_sessions_file_path, document_sessions.status AS document_sessions_status, document_sessions.chunk_count AS document_sessions_chunk_count, document_sessions.error_message AS document_sessions_error_message, document_sessions.created_at AS document_sessions_created_at, document_sessions.updated_at AS document_sessions_updated_at \n",
      "FROM document_sessions ORDER BY document_sessions.updated_at DESC\n",
      "2025-07-12 10:54:05,627 INFO sqlalchemy.engine.Engine [generated in 0.00112s] ()\n",
      "Session ID   : session-localtest-001\n",
      "Tenant ID    : tenant-xyz\n",
      "User ID      : user-123\n",
      "File Path    : /Users/gabrielohaike/Desktop/IngramDocAI/tests/sample_docs/test_contract.txt\n",
      "Status       : completed\n",
      "Chunk Count  : 7\n",
      "Error        : pymupdf package not found, please install it with `pip install pymupdf`\n",
      "Created At   : 2025-07-12 14:06:12.818386\n",
      "Updated At   : 2025-07-12 14:30:53.631506\n",
      "--------------------------------------------------------------------------------\n",
      "2025-07-12 10:54:05,634 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    }
   ],
   "source": [
    "# üîß Step 1: Required Imports\n",
    "from sqlalchemy.orm import Session\n",
    "from ingramdocai.persistence.db import Base, engine\n",
    "from ingramdocai.persistence.models import DocumentSession\n",
    "\n",
    "# üîé Step 2: Start a new DB session\n",
    "db: Session = SessionLocal()\n",
    "\n",
    "# üìÑ Step 3: Query recent sessions\n",
    "results = db.query(DocumentSession).order_by(DocumentSession.updated_at.desc()).all()\n",
    "\n",
    "# üßæ Step 4: Print summary\n",
    "for r in results:\n",
    "    print(f\"Session ID   : {r.session_id}\")\n",
    "    print(f\"Tenant ID    : {r.tenant_id}\")\n",
    "    print(f\"User ID      : {r.user_id}\")\n",
    "    print(f\"File Path    : {r.file_path}\")\n",
    "    print(f\"Status       : {r.status}\")\n",
    "    print(f\"Chunk Count  : {r.chunk_count}\")\n",
    "    print(f\"Error        : {r.error_message}\")\n",
    "    print(f\"Created At   : {r.created_at}\")\n",
    "    print(f\"Updated At   : {r.updated_at}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# ‚úÖ Step 5: Optional: close connection when done\n",
    "db.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
